{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification de terrains\n",
    "\n",
    "## Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On initialise les variables de base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 15\n",
    "IMG_HEIGHT = 600\n",
    "IMG_WIDTH = 600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de pouvoir modifier ces paramètres, on ajoute à notre script deux arguments facultatifs permettant la modification du nombre d'epochs et la taille du batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ArgumentParser()\n",
    "parser.add_argument(\"-e\", \"--epochs\", dest=\"EPOCHS\", help=\"Specify the number of epochs\", type=int)\n",
    "parser.add_argument(\"-b\", \"--batch\", dest=\"BATCH_SIZE\", help=\"Specify the batch size\", type=int)\n",
    "args = parser.parse_args()\n",
    "if args.EPOCHS:\n",
    "    EPOCHS = args.EPOCHS\n",
    "if args.BATCH_SIZE:\n",
    "    BATCH_SIZE = args.BATCH_SIZE\n",
    "\n",
    "print(\"EPOCHS = %d\" % EPOCHS)\n",
    "print(\"BATCH_SIZE = %d\" % BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée ensuite notre ImageDataGenerator qui s'occuppe de lire des images sur disque et les prétraiter dans les tenseurs appropriés. Il mettra également en place des générateurs qui convertiront ces images en lots de tenseurs, ce qui sera utile lors de la formation du réseau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_generator = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    rotation_range=45,\n",
    "    width_shift_range=.15,\n",
    "    height_shift_range=.15,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.5\n",
    ")\n",
    "\n",
    "validation_image_generator = ImageDataGenerator(\n",
    "    rescale=1. / 255\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après avoir défini les générateurs d'images de formation et de validation, la méthode flow_from_directory charge les images du disque, applique un redimensionnement et redimensionne les images dans les dimensions requises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = train_image_generator.flow_from_directory(\n",
    "    directory='data/training/',\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_data_gen = validation_image_generator.flow_from_directory(\n",
    "    directory='data/validation/',\n",
    "    target_size=(600, 600),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois les données traîtées, on peut construire notre modèle\n",
    "Celui-ci se compose de trois blocs de convolution avec une couche de pool maximum dans chacun d'eux. Il y a une couche entièrement connectée avec 512 unités sur le dessus qui est activée par une fonction d'activation de la réluctance. Le modèle produit des probabilités de classe basées sur une classification binaire par la fonction d'activation sigmoïde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle est ensuite compilé, nous avons choisi l'optimiseur ADAM et la fonction de perte \"binary_crossentropy\". \n",
    "Pour visualiser la précision de l'entraînement et de la validation pour chaque epoch d'entraînement, on passe l'argument \"metrics\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est possible à tout moment de voir les différentes couches que contient notre modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "    train_data_gen,\n",
    "    steps_per_epoch=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_data_gen,\n",
    "    validation_steps=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois notre générateur entraîné, on récupère les résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise ensuite les résultats de notre entraînement afin de réaliser un graphique récapitulatif de la précision de notre classificateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainsi que les pertes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On sauvegarde ensuite notre graphique ainsi que notre modèle entraîné pour des utilisations futures et on finit par afficher le graphique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filename = \"../models/MODEL_E\" + str(EPOCHS) + \"_B\" + str(BATCH_SIZE)\n",
    "\n",
    "plt.savefig(filename + \".png\")\n",
    "model.save(filename + \".h5\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification de nos données\n",
    "On crée également un jeu de test et on fait prédire à notre modèle entraîné la classe à laquelle il pense que l'image appartient (\"terrain\" ou \"others\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# FUNCTIONS\n",
    "def test_images(model, path):\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith(('.jpg', '.png', '.tif')):\n",
    "            img = image.load_img(os.path.join(path, file))\n",
    "            img = image.img_to_array(img)\n",
    "            img = np.expand_dims(img, axis=0)\n",
    "            result = model.predict_classes(img)\n",
    "            print(\"[\" + (\"Other\", \"Terrain\")[result[0][0] == 1] + \"] \" + file + \" (\" + str(result[0][0]) + \")\")\n",
    "\n",
    "\n",
    "# GET ARGS\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument(\"model\", help=\"Model file to load\", metavar=\"FILE\")\n",
    "args = parser.parse_args()\n",
    "if not os.path.exists(args.model):\n",
    "    print(\"Erreur: veuillez spécifier un nom de modèle à charger valide!\")\n",
    "    exit(1)\n",
    "\n",
    "# On charge notre modèle existant\n",
    "model = load_model(args.model)\n",
    "\n",
    "# On le recompile\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# PART 3: TEST MODEL\n",
    "print(\"--------------------- TERRAINS ---------------------\")\n",
    "test_images(model, 'data/test/terrains/')\n",
    "\n",
    "print(\"--------------------- NOT A TERRAIN ---------------------\")\n",
    "test_images(model, 'data/test/others/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
